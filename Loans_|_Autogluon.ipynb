{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcl347/JModel_Kaggle/blob/main/Loans_%7C_Autogluon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjCNmeUKq6d9"
      },
      "source": [
        "# AutoGluon Tabular v1.4 Extreme Preset and Ensemble Models\n",
        "\n",
        "This notebook uses AutoGluon Tabular v1.4 with the Extreme preset to tackle the loan default prediction task in Kaggle Playground Series S5E11.\n",
        "\n",
        "- Competition overview:  \n",
        "  https://www.kaggle.com/competitions/playground-series-s5e11/overview\n",
        "\n",
        "- Related discussion threads for this approach:  \n",
        "  - Discussion 617692 (AutoGluon / ensemble strategy, results, and tips):  \n",
        "    https://www.kaggle.com/competitions/playground-series-s5e11/discussion/617692  \n",
        "  - Discussion 614986 (additional approaches and ideas):  \n",
        "    https://www.kaggle.com/competitions/playground-series-s5e11/discussion/614986  \n",
        "\n",
        "---\n",
        "\n",
        "## What AutoGluon Tabular Does\n",
        "\n",
        "AutoGluon Tabular is an AutoML framework for structured tabular data. It:\n",
        "\n",
        "- Automatically handles preprocessing  \n",
        "  - Infers feature types (numeric, categorical, text, datetime)  \n",
        "  - Deals with missing values and categorical encoding  \n",
        "\n",
        "- Trains a portfolio of models  \n",
        "  - Gradient boosted trees (LightGBM, XGBoost, CatBoost)  \n",
        "  - Linear models, k-nearest neighbors, random forests  \n",
        "  - Neural networks and tabular foundation models  \n",
        "\n",
        "- Uses bagging and stacking  \n",
        "  - Bagging: multiple folds or resamples per model to get robust out-of-fold predictions  \n",
        "  - Stacking: higher level models learn how to combine predictions from lower level models  \n",
        "\n",
        "- Builds a final weighted ensemble that often outperforms any single model\n",
        "\n",
        "The goal is to replace manual model selection and blending with a strong automatically tuned ensemble.\n",
        "\n",
        "---\n",
        "\n",
        "## The Extreme Preset (v1.4)\n",
        "\n",
        "The Extreme preset is the highest accuracy mode of AutoGluon Tabular v1.4 for small and medium sized tabular datasets. It:\n",
        "\n",
        "- Uses meta-learned hyperparameters from large meta-benchmarks  \n",
        "- Trains more models and uses deeper bagging and stacking than the best_quality preset  \n",
        "- Adds several state of the art tabular models to the ensemble:\n",
        "  - Mitra\n",
        "  - TabPFNv2\n",
        "  - TabICL\n",
        "  - RealMLP\n",
        "  - TabM\n",
        "\n",
        "For Kaggle style problems, Extreme tries to squeeze out the best ROC AUC by combining many diverse, strong base learners.\n",
        "\n",
        "---\n",
        "\n",
        "## Key New Models in the Ensemble (v1.4)\n",
        "\n",
        "These models are important additions in AutoGluon Tabular v1.4 and are used inside the Extreme preset.\n",
        "\n",
        "### Mitra\n",
        "\n",
        "- Tabular foundation model with a transformer style architecture  \n",
        "- Pretrained on large amounts of synthetic tabular data  \n",
        "- Designed to generalize well after fine tuning and capture rich feature interactions  \n",
        "\n",
        "### TabPFNv2\n",
        "\n",
        "- Based on prior data fitted networks (TabPFN)  \n",
        "- Acts like an in context learning model for tabular data  \n",
        "- Very strong on small datasets, where traditional deep models can overfit  \n",
        "\n",
        "### TabICL\n",
        "\n",
        "- Tabular foundation model specialized for in context learning on larger datasets  \n",
        "- Treats tabular prediction as \"examples plus query row produce prediction\"  \n",
        "- Focused on classification tasks and can scale better than TabPFNv2 in row count  \n",
        "\n",
        "### RealMLP\n",
        "\n",
        "- High performance MLP based tabular model  \n",
        "- Uses architectural and training tricks tuned on many datasets  \n",
        "- Often competitive with gradient boosted trees, especially when the signal is friendly to neural networks  \n",
        "\n",
        "### TabM\n",
        "\n",
        "- Parameter efficient ensemble of MLPs inside a single network  \n",
        "- Produces multiple predictions per sample internally and combines them  \n",
        "- Captures ensemble diversity without training many separate models  \n",
        "\n",
        "---\n",
        "\n",
        "## Why Use This Stack For This Competition?\n",
        "\n",
        "For this loan default prediction task:\n",
        "\n",
        "- Classic models in AutoGluon (gradient boosted trees, linear models, random forests) provide solid baselines  \n",
        "- The foundation models and advanced MLPs (Mitra, TabPFNv2, TabICL, RealMLP, TabM) capture more complex non linear structure  \n",
        "- The Extreme preset bags and stacks all of these, then learns the best combination based on validation ROC AUC\n",
        "\n",
        "This gives a strong meta learned ensemble that can outperform a manually tuned blend of logistic regression, LightGBM, and XGBoost, while keeping the training code relatively simple.\n",
        "\n",
        "\n",
        "## What AutoGluon Tabular Does\n",
        "\n",
        "AutoGluon Tabular is an AutoML framework for structured tabular data. It:\n",
        "\n",
        "- Automatically handles preprocessing  \n",
        "  - Infers feature types (numeric, categorical, text, datetime)  \n",
        "  - Deals with missing values and categorical encoding  \n",
        "\n",
        "- Trains a portfolio of models  \n",
        "  - Gradient boosted trees (LightGBM, XGBoost, CatBoost)  \n",
        "  - Linear models, k-nearest neighbors, random forests  \n",
        "  - Neural networks and tabular foundation models  \n",
        "\n",
        "- Uses bagging and stacking  \n",
        "  - Bagging: multiple folds or resamples per model to get robust out-of-fold predictions  \n",
        "  - Stacking: higher level models learn how to combine predictions from lower level models  \n",
        "\n",
        "- Builds a final weighted ensemble that often outperforms any single model\n",
        "\n",
        "The goal is to replace manual model selection and blending with a strong automatically tuned ensemble.\n",
        "\n",
        "---\n",
        "\n",
        "## The Extreme Preset (version 1.4)\n",
        "\n",
        "The Extreme preset is the highest accuracy mode of AutoGluon Tabular version 1.4 for small and medium sized tabular datasets. It:\n",
        "\n",
        "- Uses meta-learned hyperparameters from large meta-benchmarks  \n",
        "- Trains more models and uses deeper bagging and stacking than the best_quality preset  \n",
        "- Adds several state of the art tabular models to the ensemble:\n",
        "  - Mitra\n",
        "  - TabPFNv2\n",
        "  - TabICL\n",
        "  - RealMLP\n",
        "  - TabM\n",
        "\n",
        "For Kaggle style problems, Extreme tries to squeeze out the best ROC AUC by combining many diverse, strong base learners.\n",
        "\n",
        "---\n",
        "\n",
        "## Key New Models in the Ensemble (version 1.4)\n",
        "\n",
        "These models are important additions in AutoGluon Tabular version 1.4 and are used inside the Extreme preset.\n",
        "\n",
        "### Mitra\n",
        "\n",
        "- Tabular foundation model with a transformer style architecture  \n",
        "- Pretrained on large amounts of synthetic tabular data  \n",
        "- Designed to generalize well after fine tuning and capture rich feature interactions  \n",
        "\n",
        "### TabPFNv2\n",
        "\n",
        "- Based on prior data fitted networks (TabPFN)  \n",
        "- Acts like an in context learning model for tabular data  \n",
        "- Very strong on small datasets, where traditional deep models can overfit  \n",
        "\n",
        "### TabICL\n",
        "\n",
        "- Tabular foundation model specialized for in context learning on larger datasets  \n",
        "- Treats tabular prediction as \"examples plus query row produce prediction\"  \n",
        "- Focused on classification tasks and can scale better than TabPFNv2 in row count  \n",
        "\n",
        "### RealMLP\n",
        "\n",
        "- High performance MLP based tabular model  \n",
        "- Uses architectural and training tricks tuned on many datasets  \n",
        "- Often competitive with gradient boosted trees, especially when the signal is friendly to neural networks  \n",
        "\n",
        "### TabM\n",
        "\n",
        "- Parameter efficient ensemble of MLPs inside a single network  \n",
        "- Produces multiple predictions per sample internally and combines them  \n",
        "- Captures ensemble diversity without training many separate models  \n",
        "\n",
        "---\n",
        "\n",
        "## Why Use This Stack For This Competition?\n",
        "\n",
        "For this loan default prediction task:\n",
        "\n",
        "- Classic models in AutoGluon (gradient boosted trees, linear models, random forests) provide solid baselines  \n",
        "- The foundation models and advanced MLPs (Mitra, TabPFNv2, TabICL, RealMLP, TabM) capture more complex non linear structure  \n",
        "- The Extreme preset bags and stacks all of these, then learns the best combination based on validation ROC AUC\n",
        "\n",
        "This gives a strong meta learned ensemble that can outperform a manually tuned blend of logistic regression, LightGBM, and XGBoost, while keeping the training code relatively simple.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "oTkvinegrggN",
        "outputId": "93880622-ba1e-447b-faed-906b519b7dfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5b62896-bd81-49cc-88f6-0c64e4e15c65\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5b62896-bd81-49cc-88f6-0c64e4e15c65\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"jmodel\",\"key\":\"9636a7ab466d9bb15529bbcc8071a87b\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload kaggle.json from your local machine\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KVtrToVTsdUO"
      },
      "outputs": [],
      "source": [
        "import os, zipfile\n",
        "\n",
        "# Make the .kaggle directory and move kaggle.json into it\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "# Set correct permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Install Kaggle CLI\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EKl3YeXsh7F",
        "outputId": "dc693fde-eaca-4952-b097-9a1fa248fd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                                 deadline             category              reward  teamCount  userHasEntered  \n",
            "----------------------------------------------------------------------------------  -------------------  ---------------  -----------  ---------  --------------  \n",
            "https://www.kaggle.com/competitions/hull-tactical-market-prediction                 2025-12-15 23:59:00  Featured         100,000 Usd       2311            True  \n",
            "https://www.kaggle.com/competitions/vesuvius-challenge-surface-detection            2026-02-13 23:59:00  Research         100,000 Usd        103           False  \n",
            "https://www.kaggle.com/competitions/google-tunix-hackathon                          2026-01-12 23:59:00  Featured         100,000 Usd         47           False  \n",
            "https://www.kaggle.com/competitions/csiro-biomass                                   2026-01-28 23:59:00  Research          75,000 Usd       1217           False  \n",
            "https://www.kaggle.com/competitions/recodai-luc-scientific-image-forgery-detection  2026-01-15 23:59:00  Research          55,000 Usd        563           False  \n",
            "https://www.kaggle.com/competitions/MABe-mouse-behavior-detection                   2025-12-15 23:59:00  Research          50,000 Usd       1022           False  \n",
            "https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction               2025-12-03 23:59:00  Featured          50,000 Usd        812           False  \n",
            "https://www.kaggle.com/competitions/cafa-6-protein-function-prediction              2026-02-02 23:59:00  Research          50,000 Usd        682           False  \n",
            "Downloading playground-series-s5e11.zip to /content\n",
            "  0% 0.00/19.3M [00:00<?, ?B/s]\n",
            "100% 19.3M/19.3M [00:00<00:00, 1.62GB/s]\n"
          ]
        }
      ],
      "source": [
        "# List competitions just to confirm it works (optional)\n",
        "!kaggle competitions list | head\n",
        "\n",
        "# Download the data for the competition\n",
        "!kaggle competitions download -c playground-series-s5e11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CbM9SjosmYF",
        "outputId": "2f1b0424-672e-4937-9e51-b5bfd5b1e966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  playground-series-s5e11.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip -o playground-series-s5e11.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "FdiPt4easpZi",
        "outputId": "9be44c69-2465-4b46-dfe7-544bc4db0981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(593994, 13) (254569, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
              "0   0       29367.99                 0.084           736      2528.42   \n",
              "1   1       22108.02                 0.166           636      4593.10   \n",
              "2   2       49566.20                 0.097           694     17005.15   \n",
              "3   3       46858.25                 0.065           533      4682.48   \n",
              "4   4       25496.70                 0.053           665     12184.43   \n",
              "\n",
              "   interest_rate  gender marital_status education_level employment_status  \\\n",
              "0          13.67  Female         Single     High School     Self-employed   \n",
              "1          12.92    Male        Married        Master's          Employed   \n",
              "2           9.76    Male         Single     High School          Employed   \n",
              "3          16.10  Female         Single     High School          Employed   \n",
              "4          10.21    Male        Married     High School          Employed   \n",
              "\n",
              "         loan_purpose grade_subgrade  loan_paid_back  \n",
              "0               Other             C3             1.0  \n",
              "1  Debt consolidation             D3             0.0  \n",
              "2  Debt consolidation             C5             1.0  \n",
              "3  Debt consolidation             F1             1.0  \n",
              "4               Other             D1             1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d587b5f9-d4d7-40c5-a586-29da2812813e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>annual_income</th>\n",
              "      <th>debt_to_income_ratio</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>loan_amount</th>\n",
              "      <th>interest_rate</th>\n",
              "      <th>gender</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>education_level</th>\n",
              "      <th>employment_status</th>\n",
              "      <th>loan_purpose</th>\n",
              "      <th>grade_subgrade</th>\n",
              "      <th>loan_paid_back</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>29367.99</td>\n",
              "      <td>0.084</td>\n",
              "      <td>736</td>\n",
              "      <td>2528.42</td>\n",
              "      <td>13.67</td>\n",
              "      <td>Female</td>\n",
              "      <td>Single</td>\n",
              "      <td>High School</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Other</td>\n",
              "      <td>C3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>22108.02</td>\n",
              "      <td>0.166</td>\n",
              "      <td>636</td>\n",
              "      <td>4593.10</td>\n",
              "      <td>12.92</td>\n",
              "      <td>Male</td>\n",
              "      <td>Married</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Employed</td>\n",
              "      <td>Debt consolidation</td>\n",
              "      <td>D3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>49566.20</td>\n",
              "      <td>0.097</td>\n",
              "      <td>694</td>\n",
              "      <td>17005.15</td>\n",
              "      <td>9.76</td>\n",
              "      <td>Male</td>\n",
              "      <td>Single</td>\n",
              "      <td>High School</td>\n",
              "      <td>Employed</td>\n",
              "      <td>Debt consolidation</td>\n",
              "      <td>C5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>46858.25</td>\n",
              "      <td>0.065</td>\n",
              "      <td>533</td>\n",
              "      <td>4682.48</td>\n",
              "      <td>16.10</td>\n",
              "      <td>Female</td>\n",
              "      <td>Single</td>\n",
              "      <td>High School</td>\n",
              "      <td>Employed</td>\n",
              "      <td>Debt consolidation</td>\n",
              "      <td>F1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25496.70</td>\n",
              "      <td>0.053</td>\n",
              "      <td>665</td>\n",
              "      <td>12184.43</td>\n",
              "      <td>10.21</td>\n",
              "      <td>Male</td>\n",
              "      <td>Married</td>\n",
              "      <td>High School</td>\n",
              "      <td>Employed</td>\n",
              "      <td>Other</td>\n",
              "      <td>D1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d587b5f9-d4d7-40c5-a586-29da2812813e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d587b5f9-d4d7-40c5-a586-29da2812813e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d587b5f9-d4d7-40c5-a586-29da2812813e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cc0bb5f8-9e07-4df4-9448-650333adfd51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc0bb5f8-9e07-4df4-9448-650333adfd51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cc0bb5f8-9e07-4df4-9448-650333adfd51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xPoLwzJq4ZY",
        "outputId": "9a5dd04d-dcf2-4e72-f9f9-2cb67acfeba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn<1.7.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.7.0,>=1.6.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.7.0,>=1.6.1) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.7.0,>=1.6.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.7.0,>=1.6.1) (3.6.0)\n",
            "sklearn version: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Upgrade scikit-learn to a version that has `get_tags` (needed by AutoGluon 1.4)\n",
        "!pip install -U \"scikit-learn>=1.6.1,<1.7.0\"\n",
        "\n",
        "import sklearn\n",
        "print(\"sklearn version:\", sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPTuBWcirDs7",
        "outputId": "a944f78f-7518-46b4-ee97-1e0fcde6e904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hXGBoost version: 2.1.4\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m216 packages\u001b[0m \u001b[2min 2.23s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m62 packages\u001b[0m \u001b[2min 19.55s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m10 packages\u001b[0m \u001b[2min 939ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m62 packages\u001b[0m \u001b[2min 223ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1madagio\u001b[0m\u001b[2m==0.2.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiohttp-cors\u001b[0m\u001b[2m==0.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-common\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-core\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-features\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-multimodal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-tabular\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-timeseries\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboto3\u001b[0m\u001b[2m==1.40.74\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbotocore\u001b[0m\u001b[2m==1.40.74\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcatboost\u001b[0m\u001b[2m==1.2.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorful\u001b[0m\u001b[2m==0.5.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcoreforecast\u001b[0m\u001b[2m==0.0.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdistlib\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meinx\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfugue\u001b[0m\u001b[2m==0.9.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgluonts\u001b[0m\u001b[2m==0.16.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.25.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning\u001b[0m\u001b[2m==2.5.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.15.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmlforecast\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmodel-index\u001b[0m\u001b[2m==0.1.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnlpaug\u001b[0m\u001b[2m==1.1.11\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-ml-py3\u001b[0m\u001b[2m==7.352.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencensus\u001b[0m\u001b[2m==0.11.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencensus-context\u001b[0m\u001b[2m==0.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopendatalab\u001b[0m\u001b[2m==0.0.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenmim\u001b[0m\u001b[2m==0.3.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenxlab\u001b[0m\u001b[2m==0.0.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mordered-set\u001b[0m\u001b[2m==4.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpdf2image\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpy-spy\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpycryptodome\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytesseract\u001b[0m\u001b[2m==0.3.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytorch-lightning\u001b[0m\u001b[2m==2.5.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytorch-metric-learning\u001b[0m\u001b[2m==2.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mray\u001b[0m\u001b[2m==2.44.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1ms3transfer\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseqeval\u001b[0m\u001b[2m==1.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstatsforecast\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboardx\u001b[0m\u001b[2m==2.6.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.22\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0+cu126\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.7.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0+cu126\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.49.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriad\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mutilsforecast\u001b[0m\u001b[2m==0.2.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mvirtualenv\u001b[0m\u001b[2m==20.35.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwindow-ops\u001b[0m\u001b[2m==0.0.15\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Make sure xgboost is on a version AutoGluon 1.4 plays nicely with\n",
        "!pip install -q \"xgboost<3.0.0\"\n",
        "\n",
        "import xgboost\n",
        "print(\"XGBoost version:\", xgboost.__version__)  # should now be 2.x\n",
        "\n",
        "# Try to install AutoGluon Tabular 1.4.x with all tabular extras\n",
        "!uv pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b83t14d6rHab",
        "outputId": "ce82d062-1826-4627-85b3-66247b5393b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preset alias specified: 'extreme' maps to 'extreme_quality'.\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          12\n",
            "Memory Avail:       50.70 GB / 52.96 GB (95.7%)\n",
            "Disk Space Avail:   192.71 GB / 235.68 GB (81.8%)\n",
            "===================================================\n",
            "Presets specified: ['extreme']\n",
            "`extreme` preset uses a dynamic portfolio based on dataset size...\n",
            "\tDetected data size: large (>30000 samples), using `zeroshot` portfolio (identical to 'best_quality' preset).\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 6250s of the 25000s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-11-17 21:45:35,032\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutogluonModels_extreme/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Beginning AutoGluon training ... Time limit = 6246s\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels_extreme/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Train Data Rows:    527994\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Train Data Columns: 16\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Label Column:       loan_paid_back\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tAvailable Memory:                    51098.70 MB\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tTrain Data (Original)  Memory Usage: 207.06 MB (0.4% of available memory)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('category', []) : 1 | ['credit_score_band']\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('float', [])    : 8 | ['annual_income', 'debt_to_income_ratio', 'loan_amount', 'interest_rate', 'loan_to_income', ...]\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('int', [])      : 1 | ['credit_score']\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('object', [])   : 6 | ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', ...]\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('category', []) : 7 | ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', ...]\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('float', [])    : 8 | ['annual_income', 'debt_to_income_ratio', 'loan_amount', 'interest_rate', 'loan_to_income', ...]\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t\t('int', [])      : 1 | ['credit_score']\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t2.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t16 features in original data used to generate 16 features in processed data.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tTrain Data (Processed) Memory Usage: 39.78 MB (0.1% of available memory)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Data preprocessing and feature engineering runtime = 2.42s ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4161.41s of the 6243.67s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.58%)\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m 1 warning generated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.250308\n",
            "\u001b[36m(_ray_fit pid=2376)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.250115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=2880)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2880)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.253826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=3250)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=3250)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.254251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=3616)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=3616)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.258725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=3967)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=3967)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.253784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=4229)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=4229)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.252323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=4524)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=4524)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.25415\n",
            "\u001b[36m(_ray_fit pid=4524)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.25404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=4971)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9149\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t525.04s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t73.87s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 3626.16s of the 5708.42s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.59%)\n",
            "\u001b[36m(_ray_fit pid=5250)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=5250)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.242809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=5572)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=5572)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.24572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=5885)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=5885)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.246263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=6139)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=6139)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.250601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=6438)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=6438)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.245691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=6759)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=6759)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.244085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=7067)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=7067)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.245068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=7364)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=7364)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.24423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9215\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t431.09s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t56.63s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3186.21s of the 5268.47s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9123\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t78.5s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t18.18s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3088.25s of the 5170.51s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9114\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t111.77s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t21.72s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 2953.51s of the 5035.77s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.37%)\n",
            "\u001b[36m(_ray_fit pid=8823)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=8823)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=8985)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=8985)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=9143)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=9143)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=9305)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=9305)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=9467)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=9467)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=9629)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=9629)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=9791)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=9791)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=9949)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=9949)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9167\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t116.4s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.35s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2834.69s of the 4916.94s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9117\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t19.35s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t16.81s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2797.25s of the 4879.51s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9115\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t22.51s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t18.7s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2754.78s of the 4837.03s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.97%)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.913\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t2003.14s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t3.8s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 748.52s of the 2830.78s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.79%)\n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:42:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20086)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:42:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20160)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:42:54] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20241)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:43:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20321)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:43:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20395)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:43:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20482)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:43:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20558)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [22:43:28] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=20636)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9208\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t51.58s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t1.05s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 694.30s of the 2776.55s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.53%)\n",
            "\u001b[36m(_ray_fit pid=20795)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "\u001b[36m(_ray_fit pid=21164)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "\u001b[36m(_ray_fit pid=21515)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "\u001b[36m(_ray_fit pid=21871)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "\u001b[36m(_ray_fit pid=22627)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "\u001b[36m(_ray_fit pid=23004)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "\u001b[36m(_ray_fit pid=23380)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9121\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t567.17s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t2.67s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 124.37s of the 2206.63s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.64%)\n",
            "\u001b[36m(_ray_fit pid=23817)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=23817)\u001b[0m \tRan out of time, early stopping on iteration 170. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=23817)\u001b[0m \t[170]\tvalid_set's binary_logloss: 0.245129\n",
            "\u001b[36m(_ray_fit pid=23948)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=23948)\u001b[0m \tRan out of time, early stopping on iteration 172. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=23948)\u001b[0m \t[172]\tvalid_set's binary_logloss: 0.248588\n",
            "\u001b[36m(_ray_fit pid=24080)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=24080)\u001b[0m \tRan out of time, early stopping on iteration 172. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=24080)\u001b[0m \t[172]\tvalid_set's binary_logloss: 0.249114\n",
            "\u001b[36m(_ray_fit pid=24211)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=24211)\u001b[0m \tRan out of time, early stopping on iteration 173. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=24211)\u001b[0m \t[173]\tvalid_set's binary_logloss: 0.252767\n",
            "\u001b[36m(_ray_fit pid=24341)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=24341)\u001b[0m \tRan out of time, early stopping on iteration 174. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=24341)\u001b[0m \t[174]\tvalid_set's binary_logloss: 0.248166\n",
            "\u001b[36m(_ray_fit pid=24474)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=24474)\u001b[0m \tRan out of time, early stopping on iteration 175. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=24474)\u001b[0m \t[175]\tvalid_set's binary_logloss: 0.246519\n",
            "\u001b[36m(_ray_fit pid=24604)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=24604)\u001b[0m \tRan out of time, early stopping on iteration 171. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=24604)\u001b[0m \t[171]\tvalid_set's binary_logloss: 0.248106\n",
            "\u001b[36m(_ray_fit pid=24737)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=24737)\u001b[0m \tRan out of time, early stopping on iteration 173. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=24737)\u001b[0m \t[173]\tvalid_set's binary_logloss: 0.2469\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9197\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t136.79s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t10.52s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 416.14s of the 2065.96s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.625, 'XGBoost_BAG_L1': 0.375}\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9218\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t28.68s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2037.14s of the 2037.04s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.88%)\n",
            "\u001b[36m(_ray_fit pid=25088)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=25232)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=25365)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=25509)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=25658)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=25804)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=25952)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=26104)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9219\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t159.0s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t10.53s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 1874.31s of the 1874.22s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.89%)\n",
            "\u001b[36m(_ray_fit pid=26326)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=26456)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=26566)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=26685)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=26796)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=26912)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=27021)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=27142)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.922\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t111.84s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t4.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1759.11s of the 1759.01s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9206\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t145.8s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t20.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1591.75s of the 1591.65s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9193\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t226.98s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t24.55s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1338.84s of the 1338.74s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.69%)\n",
            "\u001b[36m(_ray_fit pid=29311)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=29311)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=29442)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=29442)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=29572)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=29572)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=29703)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=29703)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=29834)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=29834)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=29964)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=29964)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=30097)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=30097)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_ray_fit pid=30226)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=30226)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9218\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t62.58s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1273.50s of the 1273.40s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9209\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t20.75s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t17.88s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1233.43s of the 1233.34s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9209\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t26.61s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t20.25s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1185.17s of the 1185.07s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.47%)\n",
            "\u001b[36m(_ray_fit pid=34123)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9221\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t862.72s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t3.91s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 319.18s of the 319.09s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.19%)\n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:24:33] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35314)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:24:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35392)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:24:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35473)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:24:54] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35555)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:25:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35636)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:25:07] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35714)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:25:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35794)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m /usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [23:25:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m Potential solutions:\n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m This warning will only be shown once.\n",
            "\u001b[36m(_ray_fit pid=35877)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.922\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t53.42s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t1.34s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 262.88s of the 262.79s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.80%)\n",
            "\u001b[36m(_ray_fit pid=36039)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=36220)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=36399)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=36580)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=36760)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=36941)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=37122)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=37303)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9211\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t229.65s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t4.17s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 30.00s of the 29.90s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.95%)\n",
            "\u001b[36m(_ray_fit pid=37568)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=37568)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=37568)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.398666\n",
            "\u001b[36m(_ray_fit pid=37651)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=37651)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=37651)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.401354\n",
            "\u001b[36m(_ray_fit pid=37736)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=37736)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=37736)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.400067\n",
            "\u001b[36m(_ray_fit pid=37818)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=37818)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=37818)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.400318\n",
            "\u001b[36m(_ray_fit pid=37901)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=37901)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=37901)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.398822\n",
            "\u001b[36m(_ray_fit pid=37984)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=37984)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=37984)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.399811\n",
            "\u001b[36m(_ray_fit pid=38068)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=38068)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=38068)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.40037\n",
            "\u001b[36m(_ray_fit pid=38153)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\u001b[36m(_ray_fit pid=38153)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=38153)\u001b[0m \t[9]\tvalid_set's binary_logloss: 0.399857\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9215\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t50.95s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.36s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -23.90s of remaining time.\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.52, 'XGBoost_BAG_L2': 0.2, 'RandomForestGini_BAG_L2': 0.12, 'LightGBM_BAG_L2': 0.08, 'RandomForestEntr_BAG_L2': 0.04, 'NeuralNetTorch_BAG_L2': 0.04}\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.9223\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t57.32s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m AutoGluon training complete, total runtime = 6327.54s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 372.0 rows/s (66000 batch size)\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_extreme/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=1522)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    NeuralNetFastAI_BAG_L2       0.922770   0.922138     roc_auc       38.993235     228.211327  4926.063199                 4.117805                3.909201         862.723834            2       True         20\n",
            "1       WeightedEnsemble_L3       0.922722   0.922271     roc_auc       48.558914     282.610184  5751.060308                 0.006520                0.104284          57.315844            3       True         24\n",
            "2           LightGBM_BAG_L2       0.922671   0.922004     roc_auc       35.646063     228.398680  4175.174826                 0.770633                4.096554         111.835460            2       True         14\n",
            "3            XGBoost_BAG_L2       0.922578   0.922048     roc_auc       36.554815     225.637571  4116.756986                 1.679384                1.335446          53.417620            2       True         21\n",
            "4         LightGBMXT_BAG_L2       0.922373   0.921865     roc_auc       36.727735     234.827383  4222.340796                 1.852305               10.525258         159.001430            2       True         13\n",
            "5      LightGBMLarge_BAG_L2       0.922327   0.921484     roc_auc       35.002325     224.664893  4114.288479                 0.126895                0.362768          50.949113            2       True         23\n",
            "6           LightGBM_BAG_L1       0.922232   0.921465     roc_auc        6.276254      56.629953   431.089304                 6.276254               56.629953         431.089304            1       True          2\n",
            "7           CatBoost_BAG_L2       0.922219   0.921822     roc_auc       35.000940     224.438195  4125.914915                 0.125509                0.136070          62.575550            2       True         17\n",
            "8       WeightedEnsemble_L2       0.922208   0.921799     roc_auc        9.231709      57.782605   511.349064                 0.003161                0.103924          28.675867            2       True         12\n",
            "9     NeuralNetTorch_BAG_L2       0.922064   0.921141     roc_auc       39.188530     228.470829  4292.987828                 4.313100                4.168703         229.648463            2       True         22\n",
            "10  RandomForestGini_BAG_L2       0.921471   0.920620     roc_auc       36.164708     244.446678  4209.143730                 1.289278               20.144552         145.804365            2       True         15\n",
            "11           XGBoost_BAG_L1       0.921397   0.920835     roc_auc        2.952294       1.048728    51.583893                 2.952294                1.048728          51.583893            1       True          9\n",
            "12    ExtraTreesEntr_BAG_L2       0.921353   0.920930     roc_auc       36.165639     244.552106  4089.950994                 1.290209               20.249980          26.611628            2       True         19\n",
            "13    ExtraTreesGini_BAG_L2       0.921169   0.920858     roc_auc       36.095991     242.182801  4084.090981                 1.220561               17.880676          20.751615            2       True         18\n",
            "14  RandomForestEntr_BAG_L2       0.920735   0.919327     roc_auc       36.382195     248.851444  4290.314723                 1.506765               24.549318         226.975358            2       True         16\n",
            "15     LightGBMLarge_BAG_L1       0.919702   0.919704     roc_auc        1.885608      10.522305   136.787443                 1.885608               10.522305         136.787443            1       True         11\n",
            "16          CatBoost_BAG_L1       0.916641   0.916670     roc_auc        0.552308       0.347394   116.396122                 0.552308                0.347394         116.396122            1       True          5\n",
            "17        LightGBMXT_BAG_L1       0.915454   0.914904     roc_auc        8.241145      73.874772   525.039846                 8.241145               73.874772         525.039846            1       True          1\n",
            "18   NeuralNetFastAI_BAG_L1       0.913497   0.912975     roc_auc        6.556005       3.801983  2003.137203                 6.556005                3.801983        2003.137203            1       True          8\n",
            "19  RandomForestGini_BAG_L1       0.913069   0.912264     roc_auc        1.267111      18.176564    78.500919                 1.267111               18.176564          78.500919            1       True          3\n",
            "20    NeuralNetTorch_BAG_L1       0.912991   0.912115     roc_auc        3.204391       2.671528   567.168786                 3.204391                2.671528         567.168786            1       True         10\n",
            "21  RandomForestEntr_BAG_L1       0.912557   0.911442     roc_auc        1.433363      21.722963   111.773711                 1.433363               21.722963         111.773711            1       True          4\n",
            "22    ExtraTreesEntr_BAG_L1       0.912373   0.911537     roc_auc        1.291825      18.697455    22.514492                 1.291825               18.697455          22.514492            1       True          7\n",
            "23    ExtraTreesGini_BAG_L1       0.912324   0.911736     roc_auc        1.215126      16.808480    19.347647                 1.215126               16.808480          19.347647            1       True          6\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t6389s\t = DyStack   runtime |\t18611s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 18611s\n",
            "AutoGluon will save models to \"/content/AutogluonModels_extreme\"\n",
            "Train Data Rows:    593994\n",
            "Train Data Columns: 16\n",
            "Label Column:       loan_paid_back\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    50090.21 MB\n",
            "\tTrain Data (Original)  Memory Usage: 232.96 MB (0.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 1 | ['credit_score_band']\n",
            "\t\t('float', [])    : 8 | ['annual_income', 'debt_to_income_ratio', 'loan_amount', 'interest_rate', 'loan_to_income', ...]\n",
            "\t\t('int', [])      : 1 | ['credit_score']\n",
            "\t\t('object', [])   : 6 | ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 7 | ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', ...]\n",
            "\t\t('float', [])    : 8 | ['annual_income', 'debt_to_income_ratio', 'loan_amount', 'interest_rate', 'loan_to_income', ...]\n",
            "\t\t('int', [])      : 1 | ['credit_score']\n",
            "\t2.6s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 44.75 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 2.82s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 12402.28s of the 18608.06s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.58%)\n",
            "\t0.915\t = Validation score   (roc_auc)\n",
            "\t581.07s\t = Training   runtime\n",
            "\t87.0s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 11799.54s of the 18005.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.59%)\n",
            "\t0.9219\t = Validation score   (roc_auc)\n",
            "\t507.56s\t = Training   runtime\n",
            "\t69.42s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 11279.74s of the 17485.52s of remaining time.\n",
            "\t0.9126\t = Validation score   (roc_auc)\n",
            "\t90.51s\t = Training   runtime\n",
            "\t19.41s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 11168.46s of the 17374.24s of remaining time.\n",
            "\t0.9122\t = Validation score   (roc_auc)\n",
            "\t129.34s\t = Training   runtime\n",
            "\t23.85s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 11013.95s of the 17219.73s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.35%)\n",
            "\t0.9185\t = Validation score   (roc_auc)\n",
            "\t321.08s\t = Training   runtime\n",
            "\t0.98s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 10690.30s of the 16896.08s of remaining time.\n",
            "\t0.9118\t = Validation score   (roc_auc)\n",
            "\t22.81s\t = Training   runtime\n",
            "\t17.77s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 10648.42s of the 16854.20s of remaining time.\n",
            "\t0.9115\t = Validation score   (roc_auc)\n",
            "\t25.77s\t = Training   runtime\n",
            "\t20.04s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 10601.30s of the 16807.08s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.97%)\n",
            "\t0.913\t = Validation score   (roc_auc)\n",
            "\t2447.31s\t = Training   runtime\n",
            "\t4.29s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 8150.86s of the 14356.64s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.79%)\n",
            "\t0.9211\t = Validation score   (roc_auc)\n",
            "\t54.64s\t = Training   runtime\n",
            "\t1.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 8093.63s of the 14299.41s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.53%)\n",
            "\t0.9123\t = Validation score   (roc_auc)\n",
            "\t1832.55s\t = Training   runtime\n",
            "\t3.03s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 6258.24s of the 12464.02s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.64%)\n",
            "\t0.9214\t = Validation score   (roc_auc)\n",
            "\t508.34s\t = Training   runtime\n",
            "\t75.33s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 5738.33s of the 11944.11s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.37%)\n",
            "\t0.9185\t = Validation score   (roc_auc)\n",
            "\t166.97s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 5568.86s of the 11774.64s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.53%)\n",
            "\t0.9124\t = Validation score   (roc_auc)\n",
            "\t3040.94s\t = Training   runtime\n",
            "\t3.34s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2525.07s of the 8730.85s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.61%)\n",
            "\t0.9223\t = Validation score   (roc_auc)\n",
            "\t1665.69s\t = Training   runtime\n",
            "\t275.81s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 825.29s of the 7031.07s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.98%)\n",
            "\t0.911\t = Validation score   (roc_auc)\n",
            "\t677.73s\t = Training   runtime\n",
            "\t7.81s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 144.08s of the 6349.86s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.42%)\n",
            "\t0.913\t = Validation score   (roc_auc)\n",
            "\t46.44s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 95.22s of the 6301.00s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.58%)\n",
            "\t0.9116\t = Validation score   (roc_auc)\n",
            "\t111.69s\t = Training   runtime\n",
            "\t10.33s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1240.23s of the 6185.43s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_r131_BAG_L1': 0.643, 'XGBoost_BAG_L1': 0.214, 'LightGBM_BAG_L1': 0.143}\n",
            "\t0.9224\t = Validation score   (roc_auc)\n",
            "\t50.44s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6134.80s of the 6134.68s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.09%)\n",
            "\t0.9225\t = Validation score   (roc_auc)\n",
            "\t176.75s\t = Training   runtime\n",
            "\t11.3s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5953.50s of the 5953.37s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.09%)\n",
            "\t0.9227\t = Validation score   (roc_auc)\n",
            "\t127.15s\t = Training   runtime\n",
            "\t4.73s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 5822.67s of the 5822.55s of remaining time.\n",
            "\t0.9214\t = Validation score   (roc_auc)\n",
            "\t173.09s\t = Training   runtime\n",
            "\t29.43s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 5618.46s of the 5618.34s of remaining time.\n",
            "\t0.9203\t = Validation score   (roc_auc)\n",
            "\t275.37s\t = Training   runtime\n",
            "\t33.69s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 5306.92s of the 5306.79s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.88%)\n",
            "\t0.9226\t = Validation score   (roc_auc)\n",
            "\t140.42s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 5163.35s of the 5163.23s of remaining time.\n",
            "\t0.9217\t = Validation score   (roc_auc)\n",
            "\t24.03s\t = Training   runtime\n",
            "\t25.98s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 5111.69s of the 5111.56s of remaining time.\n",
            "\t0.9219\t = Validation score   (roc_auc)\n",
            "\t30.87s\t = Training   runtime\n",
            "\t28.66s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 5050.53s of the 5050.41s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.81%)\n",
            "\t0.9228\t = Validation score   (roc_auc)\n",
            "\t2492.17s\t = Training   runtime\n",
            "\t4.5s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2554.49s of the 2554.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.43%)\n",
            "\t0.9227\t = Validation score   (roc_auc)\n",
            "\t70.87s\t = Training   runtime\n",
            "\t1.66s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 2480.30s of the 2480.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.99%)\n",
            "\t0.9221\t = Validation score   (roc_auc)\n",
            "\t1818.24s\t = Training   runtime\n",
            "\t5.64s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 658.29s of the 658.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.14%)\n",
            "\t0.9224\t = Validation score   (roc_auc)\n",
            "\t191.74s\t = Training   runtime\n",
            "\t8.11s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 462.48s of the 462.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.88%)\n",
            "\t0.9219\t = Validation score   (roc_auc)\n",
            "\t58.03s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 401.27s of the 401.15s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.99%)\n",
            "\t0.9222\t = Validation score   (roc_auc)\n",
            "\t328.66s\t = Training   runtime\n",
            "\t5.92s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 68.78s of the 68.65s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=1.10%)\n",
            "\t0.9224\t = Validation score   (roc_auc)\n",
            "\t83.46s\t = Training   runtime\n",
            "\t2.27s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 613.48s of the -18.47s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.458, 'XGBoost_BAG_L2': 0.167, 'NeuralNetTorch_r79_BAG_L2': 0.125, 'LightGBM_BAG_L2': 0.083, 'RandomForestGini_BAG_L2': 0.083, 'RandomForestEntr_BAG_L2': 0.042, 'ExtraTreesEntr_BAG_L2': 0.042}\n",
            "\t0.9229\t = Validation score   (roc_auc)\n",
            "\t92.79s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 18722.42s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 128.6 rows/s (74250 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_extreme\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          model  score_val eval_metric  pred_time_val  \\\n",
            "0           WeightedEnsemble_L3   0.922946     roc_auc     728.725211   \n",
            "1        NeuralNetFastAI_BAG_L2   0.922809     roc_auc     624.504262   \n",
            "2                XGBoost_BAG_L2   0.922742     roc_auc     621.668251   \n",
            "3               LightGBM_BAG_L2   0.922686     roc_auc     624.736338   \n",
            "4               CatBoost_BAG_L2   0.922616     roc_auc     620.384613   \n",
            "5             LightGBMXT_BAG_L2   0.922542     roc_auc     631.300204   \n",
            "6          LightGBMLarge_BAG_L2   0.922442     roc_auc     628.110886   \n",
            "7           WeightedEnsemble_L2   0.922417     roc_auc     346.511343   \n",
            "8          LightGBM_r131_BAG_L2   0.922403     roc_auc     622.275187   \n",
            "9          LightGBM_r131_BAG_L1   0.922285     roc_auc     275.805714   \n",
            "10    NeuralNetTorch_r79_BAG_L2   0.922204     roc_auc     625.928045   \n",
            "11        NeuralNetTorch_BAG_L2   0.922068     roc_auc     625.646583   \n",
            "12         CatBoost_r177_BAG_L2   0.921944     roc_auc     620.145563   \n",
            "13        ExtraTreesEntr_BAG_L2   0.921880     roc_auc     648.663581   \n",
            "14              LightGBM_BAG_L1   0.921867     roc_auc      69.421571   \n",
            "15        ExtraTreesGini_BAG_L2   0.921653     roc_auc     645.985935   \n",
            "16      RandomForestGini_BAG_L2   0.921421     roc_auc     649.434727   \n",
            "17         LightGBMLarge_BAG_L1   0.921416     roc_auc      75.326126   \n",
            "18               XGBoost_BAG_L1   0.921133     roc_auc       1.162628   \n",
            "19      RandomForestEntr_BAG_L2   0.920295     roc_auc     653.693392   \n",
            "20         CatBoost_r177_BAG_L1   0.918507     roc_auc       0.260587   \n",
            "21              CatBoost_BAG_L1   0.918491     roc_auc       0.984004   \n",
            "22            LightGBMXT_BAG_L1   0.914976     roc_auc      86.996171   \n",
            "23       NeuralNetFastAI_BAG_L1   0.913016     roc_auc       4.292688   \n",
            "24           CatBoost_r9_BAG_L1   0.912969     roc_auc       0.179667   \n",
            "25      RandomForestGini_BAG_L1   0.912591     roc_auc      19.409870   \n",
            "26    NeuralNetTorch_r79_BAG_L1   0.912351     roc_auc       3.336565   \n",
            "27        NeuralNetTorch_BAG_L1   0.912261     roc_auc       3.028699   \n",
            "28      RandomForestEntr_BAG_L1   0.912162     roc_auc      23.848624   \n",
            "29        ExtraTreesGini_BAG_L1   0.911794     roc_auc      17.774136   \n",
            "30          LightGBM_r96_BAG_L1   0.911610     roc_auc      10.330959   \n",
            "31        ExtraTreesEntr_BAG_L1   0.911480     roc_auc      20.037606   \n",
            "32  NeuralNetFastAI_r191_BAG_L1   0.911041     roc_auc       7.808348   \n",
            "\n",
            "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
            "0   15821.409303                0.120389          92.793592            3   \n",
            "1   14722.617984                4.500300        2492.174077            2   \n",
            "2   12301.310085                1.664289          70.866177            2   \n",
            "3   12357.593355                4.732376         127.149448            2   \n",
            "4   12370.865567                0.380651         140.421660            2   \n",
            "5   12407.193013               11.296242         176.749105            2   \n",
            "6   12422.183173                8.106923         191.739265            2   \n",
            "7    2278.326611                0.121430          50.438420            2   \n",
            "8   12313.908170                2.271224          83.464262            2   \n",
            "9    1665.687996              275.805714        1665.687996            1   \n",
            "10  12559.102333                5.924083         328.658426            2   \n",
            "11  14048.684697                5.642621        1818.240790            2   \n",
            "12  12288.477076                0.141601          58.033169            2   \n",
            "13  12261.314624               28.659618          30.870716            2   \n",
            "14    507.555710               69.421571         507.555710            1   \n",
            "15  12254.475844               25.981973          24.031936            2   \n",
            "16  12403.530327               29.430765         173.086419            2   \n",
            "17    508.340718               75.326126         508.340718            1   \n",
            "18     54.644485                1.162628          54.644485            1   \n",
            "19  12505.810448               33.689430         275.366541            2   \n",
            "20    166.972412                0.260587         166.972412            1   \n",
            "21    321.078055                0.984004         321.078055            1   \n",
            "22    581.068308               86.996171         581.068308            1   \n",
            "23   2447.313214                4.292688        2447.313214            1   \n",
            "24     46.440041                0.179667          46.440041            1   \n",
            "25     90.513767               19.409870          90.513767            1   \n",
            "26   3040.940497                3.336565        3040.940497            1   \n",
            "27   1832.550373                3.028699        1832.550373            1   \n",
            "28    129.338049               23.848624         129.338049            1   \n",
            "29     22.808640               17.774136          22.808640            1   \n",
            "30    111.691972               10.330959         111.691972            1   \n",
            "31     25.773022               20.037606          25.773022            1   \n",
            "32    677.726647                7.808348         677.726647            1   \n",
            "\n",
            "    can_infer  fit_order  \n",
            "0        True         33  \n",
            "1        True         26  \n",
            "2        True         27  \n",
            "3        True         20  \n",
            "4        True         23  \n",
            "5        True         19  \n",
            "6        True         29  \n",
            "7        True         18  \n",
            "8        True         32  \n",
            "9        True         14  \n",
            "10       True         31  \n",
            "11       True         28  \n",
            "12       True         30  \n",
            "13       True         25  \n",
            "14       True          2  \n",
            "15       True         24  \n",
            "16       True         21  \n",
            "17       True         11  \n",
            "18       True          9  \n",
            "19       True         22  \n",
            "20       True         12  \n",
            "21       True          5  \n",
            "22       True          1  \n",
            "23       True          8  \n",
            "24       True         16  \n",
            "25       True          3  \n",
            "26       True         13  \n",
            "27       True         10  \n",
            "28       True          4  \n",
            "29       True          6  \n",
            "30       True         17  \n",
            "31       True          7  \n",
            "32       True         15  \n",
            "AutoGluon EXTREME OOF ROC AUC: 0.922946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  loan_paid_back\n",
              "0  593994        0.934494\n",
              "1  593995        0.978753\n",
              "2  593996        0.506093\n",
              "3  593997        0.905129\n",
              "4  593998        0.962052"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7865cdb3-54d7-4b22-99a7-3693f20e2d47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>loan_paid_back</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>593994</td>\n",
              "      <td>0.934494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>593995</td>\n",
              "      <td>0.978753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>593996</td>\n",
              "      <td>0.506093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>593997</td>\n",
              "      <td>0.905129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>593998</td>\n",
              "      <td>0.962052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7865cdb3-54d7-4b22-99a7-3693f20e2d47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7865cdb3-54d7-4b22-99a7-3693f20e2d47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7865cdb3-54d7-4b22-99a7-3693f20e2d47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4375c507-3ce5-4988-a4c5-c72bc95fcab5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4375c507-3ce5-4988-a4c5-c72bc95fcab5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4375c507-3ce5-4988-a4c5-c72bc95fcab5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 0. IMPORTS\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "# ============================================================\n",
        "# 1. BASIC CONFIG\n",
        "# ============================================================\n",
        "TARGET = \"loan_paid_back\"\n",
        "ID_COL = \"id\"\n",
        "AUTOML_PATH = \"AutogluonModels_extreme\"\n",
        "\n",
        "# If your files are in a subdirectory (e.g. \"./ps5e11\"), set it here.\n",
        "# Otherwise leave as \".\" for current directory.\n",
        "DATA_DIR = \".\"\n",
        "\n",
        "# ============================================================\n",
        "# 2. LOAD DATA (LOCAL FILES FROM KAGGLE API DOWNLOAD)\n",
        "# ============================================================\n",
        "train_path = f\"{DATA_DIR}/train.csv\"\n",
        "test_path  = f\"{DATA_DIR}/test.csv\"\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test  = pd.read_csv(test_path)\n",
        "\n",
        "# Ensure target is integer 0/1\n",
        "train[TARGET] = train[TARGET].astype(int)\n",
        "\n",
        "# ============================================================\n",
        "# 3. FEATURE ENGINEERING\n",
        "#    Using only:\n",
        "#    annual_income, debt_to_income_ratio, credit_score,\n",
        "#    loan_amount, interest_rate, gender, marital_status,\n",
        "#    education_level, employment_status, loan_purpose,\n",
        "#    grade_subgrade\n",
        "# ============================================================\n",
        "\n",
        "def add_features(df):\n",
        "    \"\"\"\n",
        "    EDA-driven feature engineering using the allowed columns.\n",
        "    AutoGluon will still see the original categorical columns\n",
        "    and handle encoding automatically.\n",
        "    \"\"\"\n",
        "    # 1) Ability-to-pay features\n",
        "    eps = 1.0  # to avoid division by zero\n",
        "    df[\"loan_to_income\"] = df[\"loan_amount\"] / (df[\"annual_income\"] + eps)\n",
        "\n",
        "    # 2) Log transforms to stabilize scale and capture diminishing returns\n",
        "    df[\"log_annual_income\"] = np.log1p(df[\"annual_income\"])\n",
        "    df[\"log_loan_amount\"] = np.log1p(df[\"loan_amount\"])\n",
        "\n",
        "    # 3) Interaction between debt load and interest rate\n",
        "    df[\"dti_x_interest\"] = df[\"debt_to_income_ratio\"] * df[\"interest_rate\"]\n",
        "\n",
        "    # 4) Credit score band (categorical)\n",
        "    credit_bins = [0, 580, 640, 700, 760, 900]\n",
        "    credit_labels = [\"very_low\", \"low\", \"fair\", \"good\", \"excellent\"]\n",
        "    df[\"credit_score_band\"] = pd.cut(\n",
        "        df[\"credit_score\"],\n",
        "        bins=credit_bins,\n",
        "        labels=credit_labels,\n",
        "        include_lowest=True\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering to train and test\n",
        "train_fe = add_features(train.copy())\n",
        "test_fe  = add_features(test.copy())\n",
        "\n",
        "# ============================================================\n",
        "# 4. PREPARE DATA FOR AUTOGluon\n",
        "# ============================================================\n",
        "# Drop ID column so it is not used as a feature\n",
        "train_ag = train_fe.drop(columns=[ID_COL])\n",
        "test_ag  = test_fe.drop(columns=[ID_COL])\n",
        "\n",
        "# Wrap in TabularDataset (adds metadata for AutoGluon)\n",
        "train_ag = TabularDataset(train_ag)\n",
        "test_ag  = TabularDataset(test_ag)\n",
        "\n",
        "# ============================================================\n",
        "# 5. DEFINE PREDICTOR (EXTREME PRESET)\n",
        "# ============================================================\n",
        "predictor = TabularPredictor(\n",
        "    label=TARGET,\n",
        "    eval_metric=\"roc_auc\",\n",
        "    path=AUTOML_PATH\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 6. FIT WITH EXTREME PRESET\n",
        "# ============================================================\n",
        "# presets=\"extreme\" is the heavy, high-accuracy preset in AutoGluon v1.4.\n",
        "# It trains many model families (GBMs, neural nets, tabular foundation models),\n",
        "# with bagging and stacking.\n",
        "#\n",
        "# time_limit is total training time in seconds.\n",
        "# ag_args_fit can control GPU usage. Here we assume 1 GPU in Colab.\n",
        "# Set num_gpus=0 to force CPU-only.\n",
        "\n",
        "predictor = predictor.fit(\n",
        "    train_data=train_ag,\n",
        "    presets=\"extreme\",\n",
        "    time_limit=25000,       # adjust as needed\n",
        "    ag_args_fit={\n",
        "        \"num_gpus\": 1      # set to 0 if you are on CPU-only\n",
        "    }\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 7. INSPECT MODELS AND VALIDATION PERFORMANCE\n",
        "# ============================================================\n",
        "lb = predictor.leaderboard(silent=True)\n",
        "print(lb)\n",
        "\n",
        "# ============================================================\n",
        "# 8. OPTIONAL: OOF ROC AUC (AutoGluon out-of-fold predictions)\n",
        "# ============================================================\n",
        "try:\n",
        "    oof_pred = predictor.predict_proba_oof(as_multiclass=False)\n",
        "    oof_auc = roc_auc_score(train[TARGET], oof_pred)\n",
        "    print(\"AutoGluon EXTREME OOF ROC AUC:\", round(oof_auc, 6))\n",
        "except Exception as e:\n",
        "    print(\"Could not compute OOF predictions (not all models are bagged).\")\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# ============================================================\n",
        "# 9. PREDICT ON TEST AND BUILD SUBMISSION\n",
        "# ============================================================\n",
        "test_pred_proba = predictor.predict_proba(test_ag, as_multiclass=False)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test[ID_COL],\n",
        "    TARGET: test_pred_proba.clip(0.0, 1.0)\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "luPb1ChwuGLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad42e8a-fdfc-4010-fd07-00abbb136a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting submission.csv to playground-series-s5e11 with message: 'AutoGluon extreme in Colab'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.25M/4.25M [00:00<00:00, 5.82MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission sent.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 10. SUBMIT TO KAGGLE COMPETITION\n",
        "# ============================================================\n",
        "# Prereqs (only need to do once per runtime):\n",
        "# 1) You have kaggle.json in ~/.kaggle/kaggle.json\n",
        "# 2) You ran:  !chmod 600 ~/.kaggle/kaggle.json\n",
        "# 3) The file \"submission.csv\" exists in the current working directory.\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "COMPETITION = \"playground-series-s5e11\"\n",
        "SUBMISSION_FILE = \"submission.csv\"\n",
        "MESSAGE = \"AutoGluon extreme in Colab\"\n",
        "\n",
        "print(f\"Submitting {SUBMISSION_FILE} to {COMPETITION} with message: '{MESSAGE}'\")\n",
        "api.competition_submit(\n",
        "    file_name=SUBMISSION_FILE,\n",
        "    message=MESSAGE,\n",
        "    competition=COMPETITION\n",
        ")\n",
        "print(\"Submission sent.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fi = predictor.feature_importance(train_fe)\n",
        "print(fi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_dCqXAGUA97",
        "outputId": "f4c8f8c4-9c08-47df-97e2-abd55912ab8f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "These features in provided data are not utilized by the predictor and will be ignored: ['id']\n",
            "Computing feature importance via permutation shuffling for 16 features using 5000 rows with 5 shuffle sets...\n",
            "\t1514.66s\t= Expected runtime (302.93s per shuffle set)\n",
            "\t819.45s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      importance    stddev       p_value  n  p99_high  \\\n",
            "employment_status       0.191806  0.011328  1.453327e-06  5  0.215131   \n",
            "debt_to_income_ratio    0.056826  0.004876  6.441856e-06  5  0.066866   \n",
            "credit_score            0.049524  0.004018  5.152240e-06  5  0.057797   \n",
            "dti_x_interest          0.008374  0.000524  1.828962e-06  5  0.009453   \n",
            "interest_rate           0.007229  0.001160  7.678873e-05  5  0.009617   \n",
            "grade_subgrade          0.006841  0.000474  2.752356e-06  5  0.007817   \n",
            "loan_amount             0.005387  0.000283  9.164347e-07  5  0.005971   \n",
            "loan_to_income          0.004676  0.000826  1.123628e-04  5  0.006378   \n",
            "annual_income           0.004530  0.000572  2.988819e-05  5  0.005709   \n",
            "log_loan_amount         0.003875  0.000240  1.750091e-06  5  0.004369   \n",
            "log_annual_income       0.003308  0.000311  9.244102e-06  5  0.003948   \n",
            "loan_purpose            0.002132  0.000282  3.599223e-05  5  0.002713   \n",
            "education_level         0.001321  0.000354  5.624172e-04  5  0.002050   \n",
            "credit_score_band       0.001225  0.000440  1.692448e-03  5  0.002131   \n",
            "marital_status          0.000649  0.000132  1.920876e-04  5  0.000920   \n",
            "gender                  0.000599  0.000151  4.436218e-04  5  0.000909   \n",
            "\n",
            "                       p99_low  \n",
            "employment_status     0.168481  \n",
            "debt_to_income_ratio  0.046786  \n",
            "credit_score          0.041252  \n",
            "dti_x_interest        0.007295  \n",
            "interest_rate         0.004841  \n",
            "grade_subgrade        0.005865  \n",
            "loan_amount           0.004803  \n",
            "loan_to_income        0.002974  \n",
            "annual_income         0.003352  \n",
            "log_loan_amount       0.003382  \n",
            "log_annual_income     0.002668  \n",
            "loan_purpose          0.001551  \n",
            "education_level       0.000593  \n",
            "credit_score_band     0.000319  \n",
            "marital_status        0.000378  \n",
            "gender                0.000289  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zL9BLAX6vVbQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afd1da16-bda8-468b-a5f7-c889ca154ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: AutogluonModels_extreme/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/version.txt (stored 0%)\n",
            "  adding: AutogluonModels_extreme/metadata.json (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/models/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F4/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F4/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F1/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F1/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F5/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F5/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F2/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F2/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F8/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F8/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl (deflated 48%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F6/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F6/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F7/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F7/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F3/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L2/S1F3/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/trainer.pkl (deflated 70%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F4/model.pkl (deflated 65%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F1/model.pkl (deflated 65%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F5/model.pkl (deflated 65%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F2/model.pkl (deflated 65%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F8/model.pkl (deflated 64%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F6/model.pkl (deflated 64%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F7/model.pkl (deflated 64%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L1/S1F3/model.pkl (deflated 64%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L2/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L2/utils/model_template.pkl (deflated 49%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L2/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F4/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F4/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F1/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F1/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F5/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F5/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F2/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F2/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F8/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F8/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F6/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F6/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F7/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F7/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F3/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L2/S1F3/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F4/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F1/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F5/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F2/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F8/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F6/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F7/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L1/S1F3/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/model.pkl (deflated 49%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/S1F1/model.pkl (deflated 78%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/model.pkl (deflated 49%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/S1F1/model.pkl (deflated 79%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L1/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F4/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F1/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F5/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F2/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F8/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/utils/model_template.pkl (deflated 45%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F6/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F7/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L1/S1F3/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F4/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F1/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F5/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F2/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F8/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F6/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F7/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_BAG_L2/S1F3/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/S1F1/model.pkl (deflated 79%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L2/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F4/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F4/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F1/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F1/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F5/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F5/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F2/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F2/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F8/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F8/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F6/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F6/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F7/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F7/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F3/model.pkl (deflated 63%)\n",
            "  adding: AutogluonModels_extreme/models/XGBoost_BAG_L1/S1F3/xgb.ubj (deflated 66%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F4/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F1/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F5/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F2/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F8/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/utils/model_template.pkl (deflated 45%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F6/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F7/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r96_BAG_L1/S1F3/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F4/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F1/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F5/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F2/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F8/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/utils/model_template.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F6/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F7/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L1/S1F3/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F4/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F4/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F1/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F1/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F5/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F5/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F2/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F2/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F8/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F8/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/utils/model_template.pkl (deflated 44%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F6/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F6/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F7/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F7/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F3/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_r191_BAG_L1/S1F3/model-internals.pkl (deflated 21%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/model.pkl (deflated 55%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/S1F1/model.pkl (deflated 75%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L2/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F4/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/model.pkl (deflated 55%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F1/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F5/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F2/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F8/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/utils/model_template.pkl (deflated 44%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F6/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F7/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L2/S1F3/model.pkl (deflated 23%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/model.pkl (deflated 49%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/S1F1/model.pkl (deflated 80%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestGini_BAG_L1/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F4/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F1/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F5/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F2/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F8/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/utils/model_template.pkl (deflated 44%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F6/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F7/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_r79_BAG_L1/S1F3/model.pkl (deflated 17%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F4/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F1/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F5/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F2/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F8/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/utils/model_template.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F6/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F7/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L2/S1F3/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/model.pkl (deflated 55%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/S1F1/model.pkl (deflated 79%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesGini_BAG_L2/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F4/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F4/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F1/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F1/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F5/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F5/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F2/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F2/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F8/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F8/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl (deflated 48%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F6/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F6/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F7/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F7/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F3/model.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetFastAI_BAG_L1/S1F3/model-internals.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/S1F1/model.pkl (deflated 78%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F4/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F1/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F5/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F2/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F8/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/utils/model_template.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F6/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F7/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_BAG_L2/S1F3/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F4/model.pkl (deflated 53%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F1/model.pkl (deflated 53%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F5/model.pkl (deflated 53%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F2/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F8/model.pkl (deflated 53%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/utils/model_template.pkl (deflated 43%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/utils/oof.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F6/model.pkl (deflated 53%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F7/model.pkl (deflated 53%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L2/S1F3/model.pkl (deflated 52%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F4/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F1/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F5/model.pkl (deflated 14%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F2/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F8/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl (deflated 48%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F6/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F7/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L1/S1F3/model.pkl (deflated 13%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F4/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F1/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F5/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F2/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F8/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/utils/model_template.pkl (deflated 47%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F6/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F7/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMXT_BAG_L1/S1F3/model.pkl (deflated 57%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L3/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L3/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L3/utils/model_template.pkl (deflated 49%)\n",
            "  adding: AutogluonModels_extreme/models/WeightedEnsemble_L3/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F4/model.pkl (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F1/model.pkl (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F5/model.pkl (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F2/model.pkl (deflated 67%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F8/model.pkl (deflated 67%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/utils/model_template.pkl (deflated 43%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/utils/oof.pkl (deflated 64%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F6/model.pkl (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F7/model.pkl (deflated 67%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r9_BAG_L1/S1F3/model.pkl (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F4/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/model.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F1/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F5/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F2/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F8/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/utils/model_template.pkl (deflated 43%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F6/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F7/model.pkl (deflated 60%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/CatBoost_r177_BAG_L1/S1F3/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F4/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F1/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F5/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F2/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F8/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F6/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F7/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBMLarge_BAG_L2/S1F3/model.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/model.pkl (deflated 49%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/S1F1/model.pkl (deflated 76%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/utils/model_template.pkl (deflated 46%)\n",
            "  adding: AutogluonModels_extreme/models/RandomForestEntr_BAG_L1/utils/oof.pkl (deflated 31%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F4/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/model.pkl (deflated 54%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F1/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F5/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F2/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F8/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/utils/model_template.pkl (deflated 45%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/utils/oof.pkl (deflated 62%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F6/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F7/model.pkl (deflated 58%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/LightGBM_r131_BAG_L2/S1F3/model.pkl (deflated 59%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F4/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F4/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/model.pkl (deflated 55%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F1/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F1/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F5/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F5/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F2/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F2/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F8/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F8/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl (deflated 48%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/utils/oof.pkl (deflated 56%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F6/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F6/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F7/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F7/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F3/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/models/NeuralNetTorch_BAG_L2/S1F3/model.pkl (deflated 20%)\n",
            "  adding: AutogluonModels_extreme/learner.pkl (deflated 68%)\n",
            "  adding: AutogluonModels_extreme/utils/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/utils/data/ (stored 0%)\n",
            "  adding: AutogluonModels_extreme/utils/data/y.pkl (deflated 86%)\n",
            "  adding: AutogluonModels_extreme/utils/data/X.pkl (deflated 50%)\n",
            "  adding: AutogluonModels_extreme/predictor.pkl (deflated 50%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5e9ff62-e102-41b3-91e6-2ee234727329\", \"AutogluonModels_extreme.zip\", 1595184210)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!zip -r AutogluonModels_extreme.zip AutogluonModels_extreme\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"AutogluonModels_extreme.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S3cVQWNqTqWh",
        "outputId": "710f8562-ec8f-4bea-a5bf-200be33d7df3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ff04f568-eb50-4622-8c2a-31208d02739c\", \"submission.csv\", 4460409)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "authorship_tag": "ABX9TyMjuoyfFdjPek6zFY7mvBbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}